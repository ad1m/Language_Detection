{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>LSTM Language Detection</center></h1>\n",
    "<h3><center>CSE 6240 - Websearch and Text Mining</center></h3>\n",
    "\n",
    "<h7><center>Adam Lieberman, Garrett Mallory, Ravish Chawla</center></h7>\n",
    "<h7><center>April 25, 2017</center></h7>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Introduction:</h4>\n",
    "<p> In this project, we will be classifiying English and French text. We'll use a LSTM model to determine the probability of a text being either English or French and use a statistical method to determine the class of the text. We've included all the code here as well as some performance metrics at the end.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Imports & helper functions </h4>\n",
    "<p>Below are the modules used in this notebook:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function;\n",
    "import sys;\n",
    "import random;\n",
    "from random import randint\n",
    "\n",
    "import numpy as np;\n",
    "\n",
    "from keras.models import Sequential;\n",
    "from keras.layers import Dense, Activation;\n",
    "from keras.layers import LSTM;\n",
    "from keras.optimizers import RMSprop;\n",
    "from keras.utils.data_utils import get_file;\n",
    "from keras.models import load_model;\n",
    "\n",
    "from sklearn.cross_validation import train_test_split;\n",
    "from sklearn.metrics import *;\n",
    "from sklearn.externals import joblib;\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import subprocess;\n",
    "import h5py;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Data:</h4>\n",
    "<p>Next, we will load in the English and French text, and lowercase the alphabet.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English corpus length: 10746\n",
      "French corpus length: 12009\n"
     ]
    }
   ],
   "source": [
    "english_text = open('data/eng.txt').read().lower()\n",
    "french_text = open('data/frn.txt').read().lower()\n",
    "\n",
    "print('English corpus length:', len(english_text))\n",
    "print('French corpus length:', len(french_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Character Set and Dictionary:</h4>\n",
    "<p>We will obtain the Charachter map for both English and French by iterating over each single-letter string and adding it to a dictionary. We create both a forward-facing dictionary and an inverse-dictionary. The purpose of this dictionary is to map the features to the feature indices in our design matrix.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_chars = sorted(list(set(english_text)))\n",
    "french_chars = sorted(list(set(french_text)))\n",
    "\n",
    "english_char_map = dict((c, i) for i, c in enumerate(english_chars))\n",
    "french_char_map = dict((c, i) for i, c in enumerate(french_chars))\n",
    "\n",
    "english_char_map_inverse = dict((i, c) for i, c in enumerate(english_chars))\n",
    "french_char_map_inverse = dict((i, c) for i, c in enumerate(french_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sentence Creation:</h4>\n",
    "<p>In the next step, we will create sentences from both English and French text in a rolling window of 40 charchters. These will be our features. After this step is complete, we will obtain a [x, 40] matrices, where each row will have length alphabet-size.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb English sequences: 3569\n",
      "nb French sequences: 3990\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "english_sentences = []\n",
    "english_next_chars = []\n",
    "for i in range(0, len(english_text) - maxlen, step):\n",
    "    english_sentences.append(english_text[i: i + maxlen])\n",
    "    english_next_chars.append(english_text[i + maxlen])\n",
    "\n",
    "french_sentences = []\n",
    "french_next_chars = []\n",
    "for i in range(0, len(french_text) - maxlen, step):\n",
    "    french_sentences.append(french_text[i: i + maxlen])\n",
    "    french_next_chars.append(french_text[i + maxlen])\n",
    "    \n",
    "print('nb English sequences:', len(english_sentences))\n",
    "print('nb French sequences:', len(french_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Design Matrix Creation:</h4>\n",
    "<p>Now we will vectorize the above matrices by creating a design matrix. This will result in a [x, 40, max-alphabet-length] matrices for both English and French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "char_len = max(len(english_chars), len(french_chars));\n",
    "\n",
    "english_x = np.zeros((len(english_sentences), maxlen, char_len), dtype=np.bool)\n",
    "english_y = np.zeros((len(english_sentences), char_len), dtype=np.bool)\n",
    "for i, sentence in enumerate(english_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        english_x[i, t, english_char_map[char]] = 1\n",
    "    english_y[i, english_char_map[english_next_chars[i]]] = 1\n",
    "    \n",
    "    \n",
    "french_x = np.zeros((len(french_sentences), maxlen, char_len), dtype=np.bool)\n",
    "french_y = np.zeros((len(french_sentences), char_len), dtype=np.bool)\n",
    "for i, sentence in enumerate(french_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        french_x[i, t, french_char_map[char]] = 1\n",
    "    french_y[i, french_char_map[french_next_chars[i]]] = 1\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train-test Split:</h4>\n",
    "<p>We need to obtain a Train/Test split from our data now. This allows us to obtain a random 20% subset of data for testing and the remaining for training.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_train_x, english_test_x, english_train_y, english_test_y = train_test_split(english_x, english_y, test_size=0.2, random_state=1024);\n",
    "french_train_x, french_test_x, french_train_y, french_test_y = train_test_split(french_x, french_y, test_size=0.2, random_state=1024);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check our results so far, let's print the shapes of our Training and testing matrices. As the results below show, both languages have [x, 40, 43] values for training, even though French has 41 total alphabet charachters. We see this because we pad the smaller language with 2 extra columns of all 0s, in order to make sure that our neural network can train properly on the same input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Shapes\n",
      "(2855, 40, 43)\n",
      "(2855, 43)\n",
      "(714, 40, 43)\n",
      "(714, 43)\n",
      "\n",
      "French Shapes\n",
      "(3192, 40, 43)\n",
      "(3192, 43)\n",
      "(798, 40, 43)\n",
      "(798, 43)\n"
     ]
    }
   ],
   "source": [
    "print('English Shapes');\n",
    "print(english_train_x.shape);\n",
    "print(english_train_y.shape);\n",
    "print(english_test_x.shape);\n",
    "print(english_test_y.shape);\n",
    "print()\n",
    "print('French Shapes');\n",
    "print(french_train_x.shape);\n",
    "print(french_train_y.shape);\n",
    "print(french_test_x.shape);\n",
    "print(french_test_y.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Testing Data:</h4>\n",
    "<p>Having obtained the test split, we need to obtain a smaller sample of 100 strings of 5 length charachters each. We do this by using a Random number generator to select a random string each time, append it to our features array, along with the label associated with it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_generate(test_x, key):\n",
    "    labels = []\n",
    "    feats = []\n",
    "    if key == \"english\": \n",
    "        labels = [1 for i in range(100)]\n",
    "    elif key == 'french': \n",
    "        labels = [0 for i in range(100)]\n",
    "    else:\n",
    "        return feats, labels;\n",
    "    \n",
    "    for i in range(100): \n",
    "        r1 = randint(0, len(test_x) - 1)\n",
    "        ind = test_x[r1]\n",
    "        \n",
    "        r2 = randint(0, len(ind) - 5)\n",
    "        \n",
    "        sub_string = ind[r2:r2+5]\n",
    "        \n",
    "        feats.append(sub_string)\n",
    "        \n",
    "    return feats,labels\n",
    "    \n",
    "english_sample, english_labels = random_generate(english_test_x, 'english');\n",
    "french_sample, french_labels = random_generate(french_test_x, 'french');\n",
    "\n",
    "test_data = np.array(english_sample + french_sample);\n",
    "test_labels = np.array(english_labels + french_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>LSTM Model Creation:</h4>\n",
    "<p>Now that we have obtained our data for training and testing, we will build a LSTM model. To do this, we will create a function that will build a Sequential LSTM model. The parameters for the model below have been tuned after testing multiple configurations with over 60 epochs each. We settled on using 256 Neurons on the LSTM layer, with a RMSProp optimizer using 0.01 Learning rate. We will show our results on how we obtained these values later.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(chars):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(None, char_len)))\n",
    "    model.add(Dense(char_len))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']);\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do a prediction on our data, we will use a log of probabilities over each charachter in a string. We will iterate over each charachter, obtain the vector associated with it along with the previous START charachters, and obtain the prediction score for it on the next charachter. Finally, we sum up the logs of these values and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_on_sample(model, test_val):\n",
    "    start = np.zeros((1, 1, char_len), dtype=bool);\n",
    "    start_prob = model.predict(start);\n",
    "\n",
    "    next_vec = start.copy()[0][0];\n",
    "    probs = [];\n",
    "\n",
    "    probs.append(start_prob[0,np.argwhere(test_val[0])[0][0]]);\n",
    "\n",
    "    for idx, vec in enumerate(test_val):\n",
    "        next_vec = np.append(next_vec, vec).reshape(1, idx+2, char_len)\n",
    "        next_prob = model.predict(next_vec);\n",
    "\n",
    "        probs.append(next_prob[0, np.argwhere(test_val[idx])[0][0]]);\n",
    "        \n",
    "    return np.sum(np.log(probs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function, we can predict the results on each test string. To do this, we pass in the string along with both the English model and the French model, obtain the probabilities, and compute the GLRT. The ratio gives us a vector of probability scores, in which we set all values >= 1 to 1, and otherwise 0. The ROC score is computed on these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_results(english_model, french_model):\n",
    "    english_preds = np.array([predict_on_sample(english_model, x) for x in test_data]);\n",
    "    french_preds = np.array([predict_on_sample(french_model, x) for x in test_data]);\n",
    "    ratio_probs = english_preds - french_preds;\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(test_labels, ratio_probs);\n",
    "    roc_auc = auc(fpr, tpr);\n",
    "    \n",
    "    print(roc_auc);\n",
    "\n",
    "    return roc_auc, fpr, tpr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write another function now to plot the ROC AUC curve. We will use this function later when we obtain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(fpr, tpr, roc_auc, title): \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.semilogx(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.semilogx([np.min(fpr[fpr != 0]),1], [np.min(fpr[fpr != 0]), 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for ' + title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Hyperparameter Tuning:</h4>\n",
    "<p> In order to do hyperparameter search, we wrote a function called train_and_predict(). We cycle though a set range of epochs and evaluate the model quality as the iterations increase. We then take the best performing model.</p>\n",
    "\n",
    "<p>Other hyperparameters tuned are the learning rate, decay rate, batch sizes used in training, and size of the LSTM layer. Some of these we tuned manually rather than create a automated function for it. Finally, we found that the best performance is given by epochs=8, learning rate=0.01, decay=0.0, layer_size=256.</p>\n",
    "\n",
    "<p>Below we display graphs showing the loss vs. epochs and accuracy vs. epochs for learning rate 0.01 as a demonstration of our parameter selection process.</p>\n",
    "<center><img src=\"http://i.imgur.com/7QhIXwl.jpg\"></center>\n",
    "<center><img src=\"http://i.imgur.com/XyPN1xj.jpg\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict(total_epochs, step_size = 3, batch_size=2512):\n",
    "    english_model = build_model(english_chars)\n",
    "    french_model = build_model(french_chars);\n",
    "    epochs_ran = 0;\n",
    "\n",
    "    for i in range(0, total_epochs, step_size):\n",
    "        history_english = english_model.fit(english_train_x, english_train_y,\n",
    "                            batch_size=batch_size, epochs=step_size, shuffle=True);\n",
    "        history_french = french_model.fit(french_train_x, french_train_y,\n",
    "                            batch_size=batch_size, epochs=step_size, shuffle=True);\n",
    "\n",
    "        \n",
    "        epochs_ran = epochs_ran + step_size;\n",
    "        \n",
    "        roc = predict_results(english_model, french_model);\n",
    "        \n",
    "        if epochs_ran >= total_epochs:\n",
    "            break;\n",
    "            \n",
    "    return [english_model, french_model, roc];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Building LSTM Model</h4>\n",
    "<p>We call our function and set 5 epochs with a step size of 5 and optimal batch size of 2512.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Build model...\n",
      "Epoch 1/5\n",
      "2855/2855 [==============================] - 3s - loss: 3.7206 - acc: 0.0221     \n",
      "Epoch 2/5\n",
      "2855/2855 [==============================] - 2s - loss: 5.3884 - acc: 0.1426     \n",
      "Epoch 3/5\n",
      "2855/2855 [==============================] - 2s - loss: 4.2558 - acc: 0.0676     \n",
      "Epoch 4/5\n",
      "2855/2855 [==============================] - 2s - loss: 3.5550 - acc: 0.1625     \n",
      "Epoch 5/5\n",
      "2855/2855 [==============================] - 2s - loss: 3.4811 - acc: 0.0550     \n",
      "Epoch 1/5\n",
      "3192/3192 [==============================] - 3s - loss: 3.8357 - acc: 0.0711     \n",
      "Epoch 2/5\n",
      "3192/3192 [==============================] - 2s - loss: 3.4972 - acc: 0.0655     \n",
      "Epoch 3/5\n",
      "3192/3192 [==============================] - 2s - loss: 4.1910 - acc: 0.1103     \n",
      "Epoch 4/5\n",
      "3192/3192 [==============================] - 2s - loss: 3.0199 - acc: 0.0840     \n",
      "Epoch 5/5\n",
      "3192/3192 [==============================] - 2s - loss: 2.9137 - acc: 0.1732     \n",
      "0.7948\n"
     ]
    }
   ],
   "source": [
    "models_1 = train_and_predict(5, 5, 2512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Building LSTM Model</h4>\n",
    "<p>After training on 5 epochs, we retrain on 12 epochs with a step size of 3 epochs for our predictions. We've done this to increase ROC and experiement with parameter tuning over our previous test.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Build model...\n",
      "Epoch 1/3\n",
      "2855/2855 [==============================] - 3s - loss: 3.8244 - acc: 0.0319     \n",
      "Epoch 2/3\n",
      "2855/2855 [==============================] - 2s - loss: 3.8091 - acc: 0.0501     \n",
      "Epoch 3/3\n",
      "2855/2855 [==============================] - 2s - loss: 4.0902 - acc: 0.0630     \n",
      "Epoch 1/3\n",
      "3192/3192 [==============================] - 4s - loss: 3.6929 - acc: 0.0592     \n",
      "Epoch 2/3\n",
      "3192/3192 [==============================] - 2s - loss: 4.6424 - acc: 0.1419     \n",
      "Epoch 3/3\n",
      "3192/3192 [==============================] - 2s - loss: 4.5772 - acc: 0.0617     \n",
      "0.8456\n",
      "Epoch 1/3\n",
      "2855/2855 [==============================] - 2s - loss: 3.1018 - acc: 0.1625     \n",
      "Epoch 2/3\n",
      "2855/2855 [==============================] - 2s - loss: 3.0159 - acc: 0.1541     \n",
      "Epoch 3/3\n",
      "2855/2855 [==============================] - 2s - loss: 3.0308 - acc: 0.1625     \n",
      "Epoch 1/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7905 - acc: 0.1604     \n",
      "Epoch 2/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7677 - acc: 0.1554     \n",
      "Epoch 3/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7589 - acc: 0.1560     \n",
      "0.8479\n",
      "Epoch 1/3\n",
      "2855/2855 [==============================] - 2s - loss: 3.0133 - acc: 0.1625     \n",
      "Epoch 2/3\n",
      "2855/2855 [==============================] - 2s - loss: 2.9974 - acc: 0.1604     \n",
      "Epoch 3/3\n",
      "2855/2855 [==============================] - 2s - loss: 2.9674 - acc: 0.1625     \n",
      "Epoch 1/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.6747 - acc: 0.1538     \n",
      "Epoch 2/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7156 - acc: 0.1441     \n",
      "Epoch 3/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7864 - acc: 0.1444     \n",
      "0.865\n",
      "Epoch 1/3\n",
      "2855/2855 [==============================] - 2s - loss: 2.9449 - acc: 0.1653     \n",
      "Epoch 2/3\n",
      "2855/2855 [==============================] - 2s - loss: 2.9600 - acc: 0.1520     \n",
      "Epoch 3/3\n",
      "2855/2855 [==============================] - 2s - loss: 3.0080 - acc: 0.1891     \n",
      "Epoch 1/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7089 - acc: 0.1598     \n",
      "Epoch 2/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.6826 - acc: 0.1526     \n",
      "Epoch 3/3\n",
      "3192/3192 [==============================] - 2s - loss: 3.7564 - acc: 0.1507     \n",
      "0.8629\n"
     ]
    }
   ],
   "source": [
    "models_2 = train_and_predict(12, 3, 2512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there was a lot of variability in the model performance, we decided to rerun these cells multiple times and save the best performing model. We use this top model though our ROC varies between 0.65 and 0.95. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_1[3][0].save('model_current_e.h5')\n",
    "models_1[3][1].save('model_current_f.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = load_model('model_current_e.h5')\n",
    "model_2 = load_model('model_current_f.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ROC Prediction:</h4>\n",
    "\n",
    "Let's obtain the ROC, False Positive Rates, and True Positive Rates, and use them to plot a ROC AUC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9476\n"
     ]
    }
   ],
   "source": [
    "roc, fpr, tpr = predict_results(model_1, model_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see around a 0.95 ROC value, which is very good. We will now plot the curve with these values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEaCAYAAAC4peh0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\newG2qzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd79025ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc_curve(fpr, tpr, roc, 'English/French Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Questions:</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
