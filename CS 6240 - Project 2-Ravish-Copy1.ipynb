{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>LSTM Language Detection</center></h1>\n",
    "<h3><center>CSE 6240 - Websearch and Text Mining</center></h3>\n",
    "\n",
    "<h7><center>Adam Lieberman, Garrett Mallory, Ravish Chawla</center></h7>\n",
    "<h7><center>April 25, 2017</center></h7>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) make 80/20 split on end and frn languages. (lower case all letters)\n",
    "2) create two lstm models (size 128)\n",
    "3) train 5 epochs, 0.2 validation split on the training samples \n",
    "4) \n",
    "4) train on 100 examples of 5 character strings from text with the right label.\n",
    "\n",
    "pass new word through lstm to get log probability. then do generative log ratio test. y = sign(pe/pj -1) to get the label. Keep scores for ROC.\n",
    "\n",
    "to get log probability, need p(t), p(r|t), p(u|tr) ... etc. Do this by passing in t, then tr then tru .... This gives you the most likely next character distribution so index into that to get the prob of \"U\" from \"tr\".\n",
    "\n",
    "pass both sets of 100 test (all 200) through both networks for the probability part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function;\n",
    "import sys;\n",
    "import random;\n",
    "from random import randint\n",
    "\n",
    "import numpy as np;\n",
    "\n",
    "from keras.models import Sequential;\n",
    "from keras.layers import Dense, Activation;\n",
    "from keras.layers import LSTM;\n",
    "from keras.optimizers import RMSprop;\n",
    "from keras.utils.data_utils import get_file;\n",
    "from sklearn.cross_validation import train_test_split;\n",
    "from sklearn.metrics import *;\n",
    "from sklearn.externals import joblib;\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English corpus length: 10746\n",
      "French corpus length: 12009\n"
     ]
    }
   ],
   "source": [
    "english_text = open('eng.txt').read().lower()\n",
    "french_text = open('frn.txt').read().lower()\n",
    "\n",
    "print('English corpus length:', len(english_text))\n",
    "print('French corpus length:', len(french_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_chars = sorted(list(set(english_text)))\n",
    "french_chars = sorted(list(set(french_text)))\n",
    "\n",
    "english_char_map = dict((c, i) for i, c in enumerate(english_chars))\n",
    "french_char_map = dict((c, i) for i, c in enumerate(french_chars))\n",
    "\n",
    "english_char_map_inverse = dict((i, c) for i, c in enumerate(english_chars))\n",
    "french_char_map_inverse = dict((i, c) for i, c in enumerate(french_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character count: 43\n",
      "French character count: 41\n",
      "not present: '\n"
     ]
    }
   ],
   "source": [
    "print('English character count:', len(english_chars))\n",
    "print('French character count:', len(french_chars))\n",
    "for c in french_chars:\n",
    "    if c not in english_chars:\n",
    "        print(\"not present:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb English sequences: 3569\n",
      "nb French sequences: 3990\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "english_sentences = []\n",
    "english_next_chars = []\n",
    "for i in range(0, len(english_text) - maxlen, step):\n",
    "    english_sentences.append(english_text[i: i + maxlen])\n",
    "    english_next_chars.append(english_text[i + maxlen])\n",
    "\n",
    "french_sentences = []\n",
    "french_next_chars = []\n",
    "for i in range(0, len(french_text) - maxlen, step):\n",
    "    french_sentences.append(french_text[i: i + maxlen])\n",
    "    french_next_chars.append(french_text[i + maxlen])\n",
    "    \n",
    "print('nb English sequences:', len(english_sentences))\n",
    "print('nb French sequences:', len(french_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "char_len = max(len(english_chars), len(french_chars));\n",
    "\n",
    "english_x = np.zeros((len(english_sentences), maxlen, char_len), dtype=np.bool)\n",
    "english_y = np.zeros((len(english_sentences), char_len), dtype=np.bool)\n",
    "for i, sentence in enumerate(english_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        english_x[i, t, english_char_map[char]] = 1\n",
    "    english_y[i, english_char_map[english_next_chars[i]]] = 1\n",
    "    \n",
    "    \n",
    "french_x = np.zeros((len(french_sentences), maxlen, char_len), dtype=np.bool)\n",
    "french_y = np.zeros((len(french_sentences), char_len), dtype=np.bool)\n",
    "for i, sentence in enumerate(french_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        french_x[i, t, french_char_map[char]] = 1\n",
    "    french_y[i, french_char_map[french_next_chars[i]]] = 1\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_train_x, english_test_x, english_train_y, english_test_y = train_test_split(english_x, english_y, test_size=0.2, random_state=1024);\n",
    "french_train_x, french_test_x, french_train_y, french_test_y = train_test_split(french_x, french_y, test_size=0.2, random_state=1024);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Shapes\n",
      "(2855, 40, 43)\n",
      "(2855, 43)\n",
      "(714, 40, 43)\n",
      "(714, 43)\n",
      "\n",
      "French Shapes\n",
      "(3192, 40, 43)\n",
      "(3192, 43)\n",
      "(798, 40, 43)\n",
      "(798, 43)\n"
     ]
    }
   ],
   "source": [
    "print('English Shapes');\n",
    "print(english_train_x.shape);\n",
    "print(english_train_y.shape);\n",
    "print(english_test_x.shape);\n",
    "print(english_test_y.shape);\n",
    "print()\n",
    "print('French Shapes');\n",
    "print(french_train_x.shape);\n",
    "print(french_train_y.shape);\n",
    "print(french_test_x.shape);\n",
    "print(french_test_y.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.all = {};\n",
    "        self.all['acc'] = [];\n",
    "        self.all['val_acc'] = [];\n",
    "        self.all['loss'] = [];\n",
    "        self.all['val_loss'] = [];\n",
    "        pass;\n",
    "    \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.all['acc'].append(logs['acc'])\n",
    "        self.all['val_acc'].append(logs['val_acc'])\n",
    "        self.all['loss'].append(logs['loss']);\n",
    "        self.all['val_loss'].append(logs['val_loss']);\n",
    "            \n",
    "        clear_output();\n",
    "        #notify_slack('Finished epoch ' + str(self.num) + ' with ' + str(logs));\n",
    "        plt.plot(self.all['acc'])\n",
    "        plt.plot(self.all['val_acc'])\n",
    "\n",
    "\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(self.all['loss'])\n",
    "        plt.plot(self.all['val_loss'])\n",
    "\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "def build_model(chars):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(None, char_len)))\n",
    "    model.add(Dense(char_len))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = RMSprop(lr=0.0001, decay=0.05)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'mse', 'mae']);\n",
    "    return model\n",
    "\n",
    "english_model = build_model(english_chars)\n",
    "french_model = build_model(french_chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2284 samples, validate on 571 samples\n",
      "Epoch 1/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.7461 - acc: 0.0394 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0454 - val_loss: 3.7385 - val_acc: 0.0665 - val_mean_squared_error: 0.0227 - val_mean_absolute_error: 0.0454\n",
      "Epoch 2/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.7328 - acc: 0.0674 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0454 - val_loss: 3.7287 - val_acc: 0.0858 - val_mean_squared_error: 0.0227 - val_mean_absolute_error: 0.0454\n",
      "Epoch 3/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.7238 - acc: 0.0854 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0454 - val_loss: 3.7207 - val_acc: 0.1016 - val_mean_squared_error: 0.0227 - val_mean_absolute_error: 0.0454\n",
      "Epoch 4/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.7163 - acc: 0.0994 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0454 - val_loss: 3.7136 - val_acc: 0.1103 - val_mean_squared_error: 0.0227 - val_mean_absolute_error: 0.0454\n",
      "Epoch 5/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.7095 - acc: 0.1073 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0454 - val_loss: 3.7071 - val_acc: 0.1191 - val_mean_squared_error: 0.0227 - val_mean_absolute_error: 0.0454\n",
      "Epoch 6/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.7031 - acc: 0.1147 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0454 - val_loss: 3.7010 - val_acc: 0.1156 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0454\n",
      "Epoch 7/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6971 - acc: 0.1217 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0454 - val_loss: 3.6951 - val_acc: 0.1173 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0454\n",
      "Epoch 8/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6912 - acc: 0.1278 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6893 - val_acc: 0.1243 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 9/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6854 - acc: 0.1349 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6835 - val_acc: 0.1296 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 10/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6796 - acc: 0.1366 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6778 - val_acc: 0.1313 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 11/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6740 - acc: 0.1388 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6722 - val_acc: 0.1366 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 12/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6684 - acc: 0.1405 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6666 - val_acc: 0.1384 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 13/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6627 - acc: 0.1432 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6609 - val_acc: 0.1436 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 14/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6570 - acc: 0.1462 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6553 - val_acc: 0.1454 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 15/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6512 - acc: 0.1489 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6495 - val_acc: 0.1454 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 16/60\n",
      "2284/2284 [==============================] - 1s - loss: 3.6454 - acc: 0.1502 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6436 - val_acc: 0.1471 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 17/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6395 - acc: 0.1532 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6377 - val_acc: 0.1506 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 18/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6336 - acc: 0.1554 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6317 - val_acc: 0.1524 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 19/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6275 - acc: 0.1576 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6257 - val_acc: 0.1541 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 20/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6214 - acc: 0.1581 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0453 - val_loss: 3.6196 - val_acc: 0.1594 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.0453\n",
      "Epoch 21/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6152 - acc: 0.1594 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.6133 - val_acc: 0.1611 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 22/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6089 - acc: 0.1602 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.6069 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 23/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.6024 - acc: 0.1611 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.6003 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 24/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5958 - acc: 0.1616 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5937 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 25/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5891 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5869 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 26/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5821 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5799 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 27/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5752 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5729 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 28/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5680 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5657 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 29/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5608 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5584 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 30/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5533 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0452 - val_loss: 3.5509 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0452\n",
      "Epoch 31/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5457 - acc: 0.1624 - mean_squared_error: 0.0225 - mean_absolute_error: 0.0451 - val_loss: 3.5433 - val_acc: 0.1629 - val_mean_squared_error: 0.0225 - val_mean_absolute_error: 0.0451\n",
      "Epoch 32/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5380 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0451 - val_loss: 3.5355 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0451\n",
      "Epoch 33/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284/2284 [==============================] - 2s - loss: 3.5302 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0451 - val_loss: 3.5276 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0451\n",
      "Epoch 34/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5222 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0451 - val_loss: 3.5196 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0451\n",
      "Epoch 35/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5141 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0451 - val_loss: 3.5114 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0451\n",
      "Epoch 36/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.5058 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0451 - val_loss: 3.5030 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0451\n",
      "Epoch 37/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.4974 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0451 - val_loss: 3.4947 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0451\n",
      "Epoch 38/60\n",
      "2284/2284 [==============================] - 2s - loss: 3.4888 - acc: 0.1624 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0450 - val_loss: 3.4860 - val_acc: 0.1629 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0450\n",
      "Epoch 39/60\n",
      "1664/2284 [====================>.........] - ETA: 0s - loss: 3.4803 - acc: 0.1623 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0450"
     ]
    }
   ],
   "source": [
    "history_english = english_model.fit(english_train_x, english_train_y,\n",
    "                    batch_size=128, epochs=60, validation_split=0.2, shuffle=True);\n",
    "history_french = french_model.fit(french_train_x, french_train_y,\n",
    "                    batch_size=128, epochs=60, validation_split=0.2, shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_generate(test_x, key):\n",
    "    labels = []\n",
    "    feats = []\n",
    "    if key == \"english\": \n",
    "        labels = [1 for i in range(100)]\n",
    "    elif key == 'french': \n",
    "        labels = [0 for i in range(100)]\n",
    "    else:\n",
    "        return feats, labels;\n",
    "    \n",
    "    for i in range(100): \n",
    "        r1 = randint(0, len(test_x) - 1)\n",
    "        ind = test_x[r1]\n",
    "        \n",
    "        r2 = randint(0, len(ind) - 5)\n",
    "        \n",
    "        sub_string = ind[r2:r2+5]\n",
    "        \n",
    "        feats.append(sub_string)\n",
    "        \n",
    "    return feats,labels\n",
    "    \n",
    "english_sample, english_labels = random_generate(english_test_x, 'english');\n",
    "french_sample, french_labels = random_generate(french_test_x, 'french');\n",
    "\n",
    "test_data = np.array(english_sample + french_sample);\n",
    "test_labels = np.array(english_labels + french_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_english.history['acc'])\n",
    "plt.plot(history_english.history['val_acc'])\n",
    "\n",
    "plt.plot(history_french.history['acc'])\n",
    "plt.plot(history_french.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['eng_train', 'eng_test', 'frn_train', 'frn_test'], loc='upper left')\n",
    "plt.savefig('accuracy_e_60___lr_0.001.png')\n",
    "\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_english.history['loss'])\n",
    "plt.plot(history_english.history['val_loss'])\n",
    "\n",
    "plt.plot(history_french.history['loss'])\n",
    "plt.plot(history_french.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['eng_train', 'eng_test', 'frn_train', 'frn_test'], loc='upper left')\n",
    "plt.savefig('loss_e_60___lr_0.001.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_on_sample(model, test_val):\n",
    "    start = np.zeros((1, 1, char_len), dtype=bool);\n",
    "    start_prob = model.predict(start);\n",
    "\n",
    "    next_vec = start.copy()[0][0];\n",
    "    probs = [];\n",
    "\n",
    "    probs.append(start_prob[0,np.argwhere(test_val[0])[0][0]]);\n",
    "\n",
    "    for idx, vec in enumerate(test_val):\n",
    "        next_vec = np.append(next_vec, vec).reshape(1, idx+2, char_len)\n",
    "        next_prob = model.predict(next_vec);\n",
    "\n",
    "        probs.append(next_prob[0, np.argwhere(test_val[idx])[0][0]]);\n",
    "        \n",
    "    return np.sum(np.log10(probs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_preds = np.array([predict_on_sample(english_model_60, x) for x in test_data]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "french_preds = np.array([predict_on_sample(french_model_60, x) for x in test_data]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio_probs = english_preds - french_preds;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio_probs_labels = ratio_probs.copy();\n",
    "ratio_probs_labels[ratio_probs_labels >= 1] = 1;\n",
    "ratio_probs_labels[ratio_probs_labels < 1] = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69999999999999996"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_labels, ratio_probs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69999999999999996"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, ratio_probs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
