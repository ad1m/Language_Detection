{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>LSTM Language Detection</center></h1>\n",
    "<h3><center>CSE 6240 - Websearch and Text Mining</center></h3>\n",
    "\n",
    "<h7><center>Adam Lieberman, Garrett Mallory, Ravish Chawla</center></h7>\n",
    "<h7><center>April 25, 2017</center></h7>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) make 80/20 split on end and frn languages. (lower case all letters)\n",
    "2) create two lstm models (size 128)\n",
    "3) train 5 epochs, 0.2 validation split on the training samples \n",
    "4) \n",
    "4) train on 100 examples of 5 character strings from text with the right label.\n",
    "\n",
    "pass new word through lstm to get log probability. then do generative log ratio test. y = sign(pe/pj -1) to get the label. Keep scores for ROC.\n",
    "\n",
    "to get log probability, need p(t), p(r|t), p(u|tr) ... etc. Do this by passing in t, then tr then tru .... This gives you the most likely next character distribution so index into that to get the prob of \"U\" from \"tr\".\n",
    "\n",
    "pass both sets of 100 test (all 200) through both networks for the probability part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function;\n",
    "import sys;\n",
    "import random;\n",
    "import numpy as np;\n",
    "\n",
    "from keras.models import Sequential;\n",
    "from keras.layers import Dense, Activation;\n",
    "from keras.layers import LSTM;\n",
    "from keras.optimizers import RMSprop;\n",
    "from keras.utils.data_utils import get_file;\n",
    "from sklearn.cross_validation import train_test_split;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English corpus length: 10746\n",
      "French corpus length: 12009\n"
     ]
    }
   ],
   "source": [
    "english_text = open('eng.txt').read().lower()\n",
    "french_text = open('frn.txt').read().lower()\n",
    "\n",
    "print('English corpus length:', len(english_text))\n",
    "print('French corpus length:', len(french_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_chars = sorted(list(set(english_text)))\n",
    "french_chars = sorted(list(set(french_text)))\n",
    "\n",
    "english_char_map = dict((c, i) for i, c in enumerate(english_chars))\n",
    "french_char_map = dict((c, i) for i, c in enumerate(french_chars))\n",
    "\n",
    "english_char_map_inverse = dict((i, c) for i, c in enumerate(english_chars))\n",
    "french_char_map_inverse = dict((i, c) for i, c in enumerate(french_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character count: 43\n",
      "French character count: 41\n",
      "not present: '\n"
     ]
    }
   ],
   "source": [
    "print('English character count:', len(english_chars))\n",
    "print('French character count:', len(french_chars))\n",
    "for c in french_chars:\n",
    "    if c not in english_chars:\n",
    "        print(\"not present:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb English sequences: 3569\n",
      "nb French sequences: 3990\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "english_sentences = []\n",
    "english_next_chars = []\n",
    "for i in range(0, len(english_text) - maxlen, step):\n",
    "    english_sentences.append(english_text[i: i + maxlen])\n",
    "    english_next_chars.append(english_text[i + maxlen])\n",
    "\n",
    "french_sentences = []\n",
    "french_next_chars = []\n",
    "for i in range(0, len(french_text) - maxlen, step):\n",
    "    french_sentences.append(french_text[i: i + maxlen])\n",
    "    french_next_chars.append(french_text[i + maxlen])\n",
    "    \n",
    "print('nb English sequences:', len(english_sentences))\n",
    "print('nb French sequences:', len(french_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "larger_len = max(len(english_chars), len(french_chars));\n",
    "\n",
    "english_x = np.zeros((len(english_sentences), maxlen, larger_len), dtype=np.bool)\n",
    "english_y = np.zeros((len(english_sentences), larger_len), dtype=np.bool)\n",
    "for i, sentence in enumerate(english_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        english_x[i, t, english_char_map[char]] = 1\n",
    "    english_y[i, english_char_map[english_next_chars[i]]] = 1\n",
    "    \n",
    "    \n",
    "french_x = np.zeros((len(french_sentences), maxlen, larger_len), dtype=np.bool)\n",
    "french_y = np.zeros((len(french_sentences), larger_len), dtype=np.bool)\n",
    "for i, sentence in enumerate(french_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        french_x[i, t, french_char_map[char]] = 1\n",
    "    french_y[i, french_char_map[french_next_chars[i]]] = 1\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_train_x, english_test_x, english_train_y, english_test_y = train_test_split(english_x, english_y, test_size=0.2, random_state=1024);\n",
    "french_train_x, french_test_x, french_train_y, french_test_y = train_test_split(french_x, french_y, test_size=0.2, random_state=1024);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Shapes\n",
      "(2855, 40, 43)\n",
      "(2855, 43)\n",
      "(714, 40, 43)\n",
      "(714, 43)\n",
      "\n",
      "French Shapes\n",
      "(3192, 40, 43)\n",
      "(3192, 43)\n",
      "(798, 40, 43)\n",
      "(798, 43)\n"
     ]
    }
   ],
   "source": [
    "print('English Shapes');\n",
    "print(english_train_x.shape);\n",
    "print(english_train_y.shape);\n",
    "print(english_test_x.shape);\n",
    "print(english_test_y.shape);\n",
    "print()\n",
    "print('French Shapes');\n",
    "print(french_train_x.shape);\n",
    "print(french_train_y.shape);\n",
    "print(french_test_x.shape);\n",
    "print(french_test_y.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "def build_model(chars):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(maxlen, larger_len)))\n",
    "    model.add(Dense(larger_len))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "english_model = build_model(english_chars)\n",
    "french_model = build_model(french_chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3192/3192 [==============================] - 2s - loss: 2.9715     \n",
      "Epoch 2/5\n",
      "3192/3192 [==============================] - 2s - loss: 2.5878     \n",
      "Epoch 3/5\n",
      "3192/3192 [==============================] - 2s - loss: 2.2998     \n",
      "Epoch 4/5\n",
      "3192/3192 [==============================] - 2s - loss: 2.0953     \n",
      "Epoch 5/5\n",
      "3192/3192 [==============================] - 2s - loss: 1.9543     \n"
     ]
    }
   ],
   "source": [
    "history_english = english_model.fit(english_train_x, english_train_y,\n",
    "                    #batch_size=128, epochs=5);\n",
    "history_french = french_model.fit(french_train_x, french_train_y,\n",
    "                    batch_size=128, epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = english_test_x[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = english_model.predict(np.reshape(sample, (1, 40, 43)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
